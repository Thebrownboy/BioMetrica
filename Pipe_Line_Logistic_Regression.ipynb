{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366b4301",
   "metadata": {},
   "source": [
    "# بسم الله الرحمن الرحيم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2144698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 10:27:54.114870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-13 10:27:54.286903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-13 10:27:54.286930: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-13 10:27:55.136803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-13 10:27:55.136956: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-13 10:27:55.136969: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/thebrownboy/anaconda3/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3acb315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/body_level_classification_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09063b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original= cleaning_data(df).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8323be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_train,all_class_test=data_spliting(df_original,1/3)\n",
    "## shuffling \n",
    "all_class_train = all_class_train.sample(frac=1.0, random_state=42)\n",
    "all_class_test = all_class_test.sample(frac=1.0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4742b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=all_class_train.drop([\"Body_Level\"],axis=1).to_numpy()\n",
    "Y_train=all_class_train[\"Body_Level\"].to_numpy()\n",
    "X_test =all_class_test.drop([\"Body_Level\"],axis=1).to_numpy()\n",
    "Y_test =all_class_test[\"Body_Level\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42bc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, scaler= data_scaling(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65948699",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test\n",
    "                                                     , Y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099adff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scaler.transform(X_val)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293e51a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2'} 0.646059580577347\n",
      "{'C': 0.01, 'penalty': 'l2'} 0.7180279956929703\n",
      "{'C': 0.1, 'penalty': 'l2'} 0.8407783417935702\n",
      "{'C': 1, 'penalty': 'l2'} 0.9280008203866071\n",
      "{'C': 10, 'penalty': 'l2'} 0.9574168076706149\n",
      "{'C': 100, 'penalty': 'l2'} 0.9716146233912731\n",
      "{'C': 200, 'penalty': 'l2'} 0.973645080244065\n",
      "{'C': 300, 'penalty': 'l2'} 0.9716146233912731\n",
      "{'C': 400, 'penalty': 'l2'} 0.9695892939547761\n",
      "{'C': 500, 'penalty': 'l2'} 0.9695892939547761\n",
      "{'C': 600, 'penalty': 'l2'} 0.9685791929446751\n",
      "{'C': 700, 'penalty': 'l2'} 0.9685791929446751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "total_samples = 986  # total number of samples\n",
    "class_0 = 127  # number of samples in class 0\n",
    "class_1 = 134  # number of samples in class 1\n",
    "class_2 = 271  # number of samples in class 2\n",
    "class_3 = 454  # number of samples in class 3\n",
    "\n",
    "class_weights = {\n",
    "    0: total_samples / (4 * class_0),\n",
    "    1: total_samples / (4 * class_1),\n",
    "    2: total_samples / (4 * class_2),\n",
    "    3: total_samples / (4 * class_3)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "reg_model = LogisticRegression(random_state=42,max_iter=1000,class_weight=class_weights)\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.001,0.01,0.1, 1, 10,100,200,300,400,500 ,600 ,700 ],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=reg_model, param_grid=param_grid, cv=None)\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Access the cv_results_ dictionary\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Print the mean test scores for each hyperparameter combination\n",
    "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(params, mean_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f699d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878048780487805"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(grid_search.best_estimator_.predict(X_test) == Y_test) / Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc58b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled= over_sampling(all_class_train,sampling_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc52235",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=oversampled.drop([\"Body_Level\"],axis=1).to_numpy()\n",
    "Y_train=oversampled[\"Body_Level\"].to_numpy()\n",
    "X_test =all_class_test.drop([\"Body_Level\"],axis=1).to_numpy()\n",
    "Y_test =all_class_test[\"Body_Level\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938a5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, scaler= data_scaling(X_train)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test\n",
    "                                                     , Y_test, test_size=0.5, random_state=42)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f36b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2'} 0.5588201405691899\n",
      "{'C': 0.01, 'penalty': 'l2'} 0.712959442332066\n",
      "{'C': 0.1, 'penalty': 'l2'} 0.8412749164650306\n",
      "{'C': 1, 'penalty': 'l2'} 0.9377261205207974\n",
      "{'C': 10, 'penalty': 'l2'} 0.9673320659062103\n",
      "{'C': 100, 'penalty': 'l2'} 0.9825210277681762\n",
      "{'C': 200, 'penalty': 'l2'} 0.9840390597995162\n",
      "{'C': 300, 'penalty': 'l2'} 0.9840390597995162\n",
      "{'C': 400, 'penalty': 'l2'} 0.9832786035257518\n",
      "{'C': 500, 'penalty': 'l2'} 0.9825210277681761\n",
      "{'C': 600, 'penalty': 'l2'} 0.9825210277681761\n",
      "{'C': 700, 'penalty': 'l2'} 0.9825210277681761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "total_samples = 986  # total number of samples\n",
    "class_0 = 127  # number of samples in class 0\n",
    "class_1 = 134  # number of samples in class 1\n",
    "class_2 = 271  # number of samples in class 2\n",
    "class_3 = 454  # number of samples in class 3\n",
    "\n",
    "class_weights = {\n",
    "    0: total_samples / (4 * class_0),\n",
    "    1: total_samples / (4 * class_1),\n",
    "    2: total_samples / (4 * class_2),\n",
    "    3: total_samples / (4 * class_3)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "reg_model = LogisticRegression(random_state=42,max_iter=1000,class_weight=class_weights)\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.001,0.01,0.1, 1, 10,100,200,300,400,500 ,600 ,700 ],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=reg_model, param_grid=param_grid, cv=None)\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Access the cv_results_ dictionary\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Print the mean test scores for each hyperparameter combination\n",
    "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(params, mean_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afbf8a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755102040816327"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(grid_search.best_estimator_.predict(X_val) == Y_val) / Y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863987c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
